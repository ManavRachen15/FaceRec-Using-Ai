{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from time import time\nimport logging\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn import metrics\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:08:03.593139Z","iopub.execute_input":"2022-06-01T11:08:03.593673Z","iopub.status.idle":"2022-06-01T11:08:09.264435Z","shell.execute_reply.started":"2022-06-01T11:08:03.593634Z","shell.execute_reply":"2022-06-01T11:08:09.263735Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# print(__doc__)\n\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n\n\n# #############################################################################\n# Download the data, if not already on disk and load it as numpy arrays\n\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel\n# positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)\ntarget_names\n\n# #############################################################################\n# Split into a training set and a test set using a stratified k fold\n\n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42)\n\n\n# #############################################################################\n# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n# dataset): unsupervised feature extraction / dimensionality reduction\nn_components = 150\n\nprint(\"Extracting the top %d eigenfaces from %d faces\"\n      % (n_components, X_train.shape[0]))\nt0 = time()\npca = PCA(n_components=n_components, svd_solver='randomized',\n          whiten=True).fit(X_train)\nprint(\"done in %0.3fs\" % (time() - t0))\n\neigenfaces = pca.components_.reshape((n_components, h, w))\n\nprint(\"Projecting the input data on the eigenfaces orthonormal basis\")\nt0 = time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time() - t0))\n\n\n# #############################################################################\n# Train a SVM classification model\n\nprint(\"Fitting the classifier to the training set\")\nt0 = time()\nparam_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\nclf = GridSearchCV(\n    SVC(kernel='rbf', class_weight='balanced'), param_grid\n)\nclf = clf.fit(X_train_pca, y_train)\nprint(\"done in %0.3fs\" % (time() - t0))\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\n\n\n# #############################################################################\n# Quantitative evaluation of the model quality on the test set\n\nprint(\"Predicting people's names on the test set\")\nt0 = time()\ny_pred = clf.predict(X_test_pca)\nprint(\"done in %0.3fs\" % (time() - t0))\n\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n\n\n# #############################################################################\n# Qualitative evaluation of the predictions using matplotlib\n\ndef plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i], size=12)\n        plt.xticks(())\n        plt.yticks(())\n\n\n# plot the result of the prediction on a portion of the test set\n\ndef title(y_pred, y_test, target_names, i):\n    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n\nprediction_titles = [title(y_pred, y_test, target_names, i)\n                     for i in range(y_pred.shape[0])]\n\nplot_gallery(X_test, prediction_titles, h, w)\n\n# plot the gallery of the most significative eigenfaces\n\neigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\nplot_gallery(eigenfaces, eigenface_titles, h, w)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:08:09.265990Z","iopub.execute_input":"2022-06-01T11:08:09.266254Z","iopub.status.idle":"2022-06-01T11:09:18.406098Z","shell.execute_reply.started":"2022-06-01T11:08:09.266217Z","shell.execute_reply":"2022-06-01T11:09:18.405469Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Task 1 Random Forest########################################################\nlf = RandomForestClassifier(max_depth=2, random_state=0)\nlf.fit(X_train_pca, y_train)\npredict = lf.predict(X_test_pca)\nprint(\"Accuracy:  {:.2f}\".format(accuracy_score(y_test,predict)))\n#############################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:18.407136Z","iopub.execute_input":"2022-06-01T11:09:18.407502Z","iopub.status.idle":"2022-06-01T11:09:18.913861Z","shell.execute_reply.started":"2022-06-01T11:09:18.407466Z","shell.execute_reply":"2022-06-01T11:09:18.913148Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Task 2 MLP ############################################################################### \n\n# Train a mlp classification model\n\nt0 = time()\nclf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(15, 10), random_state=1)\n\nclf = clf.fit(X_train_pca, y_train)\nclf.score(X_test_pca, y_test)\nprint(clf.score(X_test_pca, y_test))\nprint(\"done in %0.3fs\" % (time() - t0))\n\n##########################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:18.915735Z","iopub.execute_input":"2022-06-01T11:09:18.916951Z","iopub.status.idle":"2022-06-01T11:09:20.255310Z","shell.execute_reply.started":"2022-06-01T11:09:18.916910Z","shell.execute_reply":"2022-06-01T11:09:20.254473Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#######Task 2 exstended high parameter ############################################################\nmlp = MLPClassifier(max_iter=100)\npara={\n    'hidden_layer_sizes': [(15,10)],\n    'activation': ['tanh', 'relu', 'adam'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\n#builds a grid of potential param\nclf = GridSearchCV(mlp, para, n_jobs=-1, cv=3)\nclf.fit(X_test_pca, y_test)\n\n#best prameter set\nprint('Best parameters found:\\n', clf.best_params_)\n\n# All results\n#means = clf.cv_results_['mean_test_score']\n#stds = clf.cv_results_['std_test_score']\n#for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n#######################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:20.259444Z","iopub.execute_input":"2022-06-01T11:09:20.259808Z","iopub.status.idle":"2022-06-01T11:09:28.764522Z","shell.execute_reply.started":"2022-06-01T11:09:20.259751Z","shell.execute_reply":"2022-06-01T11:09:28.763753Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Task 2 exstended high parameter#########################################################################\n# Train a mlp classification model\nt0 = time()\nclf = MLPClassifier(solver='adam', alpha=0.0001,hidden_layer_sizes=(15, 10), random_state=1, activation='tanh', learning_rate='constant')\n\nclf = clf.fit(X_train_pca, y_train)\nclf.score(X_test_pca, y_test)\nprint(clf.score(X_test_pca, y_test))\nprint(\"done in %0.3fs\" % (time() - t0))\n#################################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:28.766334Z","iopub.execute_input":"2022-06-01T11:09:28.766838Z","iopub.status.idle":"2022-06-01T11:09:30.376189Z","shell.execute_reply.started":"2022-06-01T11:09:28.766780Z","shell.execute_reply":"2022-06-01T11:09:30.373253Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Task 3 Cnn model #####################################################################\n\n\nX_train = X_train.reshape(len(X_train), 50, 37, 1)\nX_test = X_test.reshape(len(X_test), 50, 37, 1)\n\ninput_shape = (50, 37, 1)\noutput_classes = 10\nnum_classes = 10\n\n## Build the model\n#ANN##############################################################################\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(50,37,1)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(output_classes)\n])\n\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n## Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=128)\n\n\n## Evaluate the trained model\ntest_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\nprint('\\n Test accuracy:', test_acc)\n##################################################################################\n\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()\n\nmodel.compile(optimizer=\"adam\",loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\nmodel.fit(X_train, y_train, batch_size= 128, epochs = 30)\n\n#evaluate\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"test loss:\", score[0])\nprint(\"test accuracy:\", score[1])\n###############################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:30.377235Z","iopub.execute_input":"2022-06-01T11:09:30.377661Z","iopub.status.idle":"2022-06-01T11:09:45.444778Z","shell.execute_reply.started":"2022-06-01T11:09:30.377623Z","shell.execute_reply":"2022-06-01T11:09:45.444049Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Task 4 Clustering ###################################################################\nX_train = X_train/255.0\nX_test = X_test/255.0\n\nprint(X_train.min())\nprint(X_train.max())\n\nX_train = X_train.reshape(len(X_train), -1)\nX_test = X_test.reshape(len(X_test), -1)\n\nprint(X_train.shape)\nprint(X_test.shape)\n\nkmeans = KMeans(n_clusters = 7)\nkmeans.fit(X_train)\n\nkmeans.labels_\n######################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:11:28.351079Z","iopub.execute_input":"2022-06-01T11:11:28.351369Z","iopub.status.idle":"2022-06-01T11:11:30.357671Z","shell.execute_reply.started":"2022-06-01T11:11:28.351336Z","shell.execute_reply":"2022-06-01T11:11:30.357110Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Task 4 Clustering ###################################################################\ncluster_number = [10,16,36,64,144,256]\n\ndef retrieve_info(cluster_labels,y_train):\n    reference_labels = {}\n    for i in range(len(np.unique(kmeans.labels_))):\n        index = np.where(cluster_labels == i,1,0)\n        num = np.bincount(y_train[index==1]).argmax()\n        reference_labels[i] = num\n    return reference_labels\nreference_labels = retrieve_info(kmeans.labels_,y_train)\n\ndef metrics(model,output):\n    print(\"Number of clusters is {}\".format(model.n_clusters))\n    \nfor i in cluster_number:\n    total_clusters = len(np.unique(y_test))\n    kmeans = KMeans(n_clusters = i)\n    kmeans.fit(X_train)\n    metrics(kmeans,y_train)\n   \n    # Calculating reference_labels\n    reference_labels = retrieve_info(kmeans.labels_,y_train)\n    number_labels = np.random.rand(len(kmeans.labels_))\n    for i in range(len(kmeans.labels_)):\n        number_labels[i] = reference_labels[kmeans.labels_[i]]\n            \n    print(\"Accuracy score : {}\".format(accuracy_score(number_labels,y_train)))\n    print(\"\\n\")\n    \n   ######################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:09:47.606326Z","iopub.execute_input":"2022-06-01T11:09:47.606566Z","iopub.status.idle":"2022-06-01T11:10:39.227609Z","shell.execute_reply.started":"2022-06-01T11:09:47.606531Z","shell.execute_reply":"2022-06-01T11:10:39.227061Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Task 4 Clustering ###################################################################\nwcss=[]\nfor i in cluster_number:\n    kmeans = KMeans(i)\n    kmeans.fit(X_test)\n    wcss_iter = kmeans.inertia_\n    wcss.append(wcss_iter)\n\nnumber_clusters = cluster_number\nplt.plot(number_clusters,wcss)\nplt.title('')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\n\nkmeans = KMeans(3)\ncl = kmeans.fit_predict(X_test)\n\n######################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:10:39.231730Z","iopub.execute_input":"2022-06-01T11:10:39.233775Z","iopub.status.idle":"2022-06-01T11:10:59.081133Z","shell.execute_reply.started":"2022-06-01T11:10:39.233733Z","shell.execute_reply":"2022-06-01T11:10:59.080554Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Task 4 Clustering ###################################################################\nXbush = []\n\nfor i in range(len(number_labels)):\n    if(y_train[i] == 3):\n        Xbush.append(number_labels[i])\n    \nXbush = np.array(Xbush) \nXbush\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:10:59.084551Z","iopub.execute_input":"2022-06-01T11:10:59.086207Z","iopub.status.idle":"2022-06-01T11:10:59.102059Z","shell.execute_reply.started":"2022-06-01T11:10:59.086170Z","shell.execute_reply":"2022-06-01T11:10:59.101264Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_bush = []\n\nfor i in range(len(X_test)):\n    if (y_train[i] == 3):\n        X_bush.append(X_test[i])\n\nX_bush = np.array(X_bush)\n\nX_bush_norm = X_bush / 255.0\nX_bush_norm = X_bush_norm.reshape(len(X_bush), -1)\nprint(X_bush)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:11:35.047687Z","iopub.execute_input":"2022-06-01T11:11:35.050090Z","iopub.status.idle":"2022-06-01T11:11:35.065933Z","shell.execute_reply.started":"2022-06-01T11:11:35.050046Z","shell.execute_reply":"2022-06-01T11:11:35.064651Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Task 4 Clustering ###################################################################\nX_bush = X_bush / 255.0\nX_bush = X_bush.reshape(len(X_bush), -1)\n\n\npredicted = kmeans.predict(X_bush)\nnumber_labels[predicted]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T11:11:36.747401Z","iopub.execute_input":"2022-06-01T11:11:36.747664Z","iopub.status.idle":"2022-06-01T11:11:36.759498Z","shell.execute_reply.started":"2022-06-01T11:11:36.747632Z","shell.execute_reply":"2022-06-01T11:11:36.758074Z"},"trusted":true},"execution_count":17,"outputs":[]}]}